---
layout: post
comments: true
title: "Algorithms in Machine Learning"
date: 2019-05-02
---

ML models are a tool useful to establish a relationship or find patterns in the data. As it is wisely said, all models are wrong, only some are useful. The results from the models should always be verified to make sense from the business perspective.
ML is majorly divided into two types namely, **supervised and unsupervised learning**.

## Supervised Learning

These are models that have the outcome variable defined and the objective is to reach as close as possible to this outcome variable. These are of two types i.e. **Regression and Classification**. For this, we first define an error metric to help us with our cause. We will look into this later on.

Regression Models have continuous variable as outcome while classification Models have categorical variables as outcome.

### Regression Models

- [Linear Regression](https://abhisheksanghai.github.io/2019/05/03/linear-regression) 

There are a lot of cases where we take an alternate route in order to deal with the overfitting problems. That's when the regularization comes into the picture. Regularization allows us to add a penalty parameter that slightly alters our objective function and doesn't allow us to reach the true minimum. Following are different types of regularization for Linear Regression - 

1. [Lasso Regression or L1 Regularization]()
2. [Ridge Regression or L2 Regularization]()
3. [Elastic Net Regression]()

### Classification Models

- [Logistic Regression]()
- [Decision Tree]()

## Unsupervised Learning

These models do not have any outcome variables defined rather they are majorly used for segmenting data into unknown groups with similar characteristics. All the **Clustering Models** fall under this category

(to be updated)




