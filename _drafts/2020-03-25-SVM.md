---
layout: post
comments: true
title: "Support Vector Machine"
date: 2020-03-25
---

In this post, we will be looking at the classification technique known as Support Vector Machine (SVM). SVM is one of the most effective classification algorithms and is often found difficult to understand primarily because there are various kinds of concepts that are involved at play.

So far the algorithms that we have looked at (Linear and Logistic Regression) rely on Gradient Descent to achieve optimal values. However, SVM is slightly different. We will be using gradient here as well but not exactly in the same manner. 

### Introduction

SVM gives us an option to transform the data into a higher dimension. It runs on an idea that if data is not linearly separable as per the available data, we move to a higher dimensions to find such a plane. The reason it is called support vector machine is because the identified separator plane uses the nearest data points of each class to classify and these data points are called support vectors. This way, we are using the data point from class 1 which is most similar to class 2 and similarly the other way. The image below depicts this information.

![SVM_support_vectors](/images/SVM/SVM_support_vectors.jpg)

In the above image the points nearest to the plane are called support vectors. Below is an example of how changing the data to higher dimension helps separate the classes.

![SVM_higher_dimension](/images/SVM/SVM_higher_dimension.jpg)

### Pre-Requisites

There are certain prerequisites that one should know before understanding how SVMs work. Let's look at them - 

- **Vectors and Planes** - 
1. Equation of a plane P : ax + by + cz = k (3-dimensional)

2. Normal Vector to the plane P (Vector perpendicular to the plane) : ai&#770; + bj&#770; + ck&#770;

3. Distance of a point Q(x<sub>1</sub>,y<sub>1</sub>,z<sub>1</sub>) from the plane P : &plusmn; <sup> (ax<sub>1</sub> + by<sub>1</sub> + cz<sub>1</sub> -k) </sup> &frasl; <sub> &#8730;(a<sup>2</sup> + b<sup>2</sup> + c<sup>2</sup>) </sub>

The distance would be represented with a modulus but the value itself would be (+) or (-) depending on which side of the plane the point lies.

- **Gradient** -  Gradient of a function is a vector that points towards the maximum increase of the function

- **General Fact** -  min<sub>x</sub> max<sub>&alpha;</sub> f(x,&alpha;) &ge; max<sub>&alpha;</sub> min<sub>x</sub> f(x,&alpha;)

- **Lagrangian Method** - This method is used to find optimal values of a function subject to certain constraints.

1. **Initial Form**

Objective function : min<sub>x</sub> f(x) 

Equality Constraint : h(x) = 0

In order to solve this, we need to understand that the minima of f(x) will occur when both f(x) and h(x) are tangent to each other. &Implies; **&nabla;<sub>x</sub> f = -&lambda; (&nabla;<sub>x</sub> h)** (&lambda; can be positive or negative)

therefore, in order to solve this problem, we define a new Lagrangian function, &#8466;(x,&lambda;) = f(x) + &lambda;(h(x))

Now, our objective is to just minimize this function. The conditions for this would be -

&nabla;<sub>x</sub> &#8466; = 0 and &nabla;<sub>&lambda;</sub> &#8466; = 0

&Implies; &nabla;<sub>x</sub> f = 0 and h(x) = 0 (This was our original condition as well).

The &lambda; here is called **lagrangian multiplier** and represents  <sup>&nabla; &#8466;</sup> &frasl; <sub>&nabla; h</sub> (The rate of increase of &#8466; as we relax the conditions on h)

2. **Ext1 :** It has been shown that this can be extended for multiple constraints as well which is shown below - 

Objective function : min<sub>x</sub> f(x) 

Equality Constraint : h<sub>i</sub>(x) = 0 _where_ i = {1,2,3,...,n}

In this case, the Lagrangian function would be : &#8466;(x,&lambda;<sub>1</sub>,&lambda;<sub>2</sub>,...,&lambda;<sub>n</sub>) = f(x) + &Sigma;&lambda;<sub>i</sub> h<sub>i</sub>(x)

3. **Ext2 :** Another extension of this is when we introduce inequality constraint instead of equality constraint into the picture.

Objective function : min<sub>x</sub> f(x) 

Inequality Constraint : g(x) &le; 0 

New Lagrangian function - &#8466;(x,&alpha;) = f(x) + &alpha;(g(x))

Here, If the x at which f(x) achieves minima satisfies the condition g(x) < 0 &Implies; the constraint is not required and &alpha; can be set to 0. If not, then again the minima will occur where both the functions are tangent to each other and so, g(x) = 0 (because the intersection point will lie on g(x))

&Implies; &alpha;(g(x)) = 0 always and hence the function's value at minima is again same as minima of f(x). &alpha; here is called **KKT multiplier** (KKT stands for Karush-Kuhn-Tucker)

4. **Ext3 :** Generalizing with both equality and inequality constraints - 

Objective function : min<sub>x</sub> f(x) 

Equality Constraint : h<sub>i</sub>(x) = 0 _where_ i = {1,2,3,...,n}

Inequality Constraint : g<sub>j</sub>(x) = 0 _where_ j = {1,2,3,...,m}

The Lagrangian function in this case would be, &#8466;(x,&lambda;<sub>1</sub>,&lambda;<sub>2</sub>,...,&lambda;<sub>n</sub>,&alpha;<sub>1</sub>,&alpha;<sub>2</sub>,...,&alpha;<sub>m</sub>) = f(x) + &Sigma;&lambda;<sub>i</sub> h<sub>i</sub>(x) + &Sigma;&alpha;<sub>j</sub> g<sub>j</sub>(x)

- **Primal and Dual Form** - These are two forms of objective function and we are going to look at them using the generalized form above in Ext3.

1. **Primal Form** - 

&#8466;(x,&lambda;<sub>1</sub>,&lambda;<sub>2</sub>,...,&lambda;<sub>n</sub>,&alpha;<sub>1</sub>,&alpha;<sub>2</sub>,...,&alpha;<sub>m</sub>) = f(x) + &Sigma;&lambda;<sub>i</sub> h<sub>i</sub>(x) + &Sigma;&alpha;<sub>j</sub> g<sub>j</sub>(x) subject to the corresponding equality and inequality conditions.

The primal form is : &theta;<sub>p</sub>(x) = max<sub>&alpha;,&lambda;</sub> &#8466;(x,&lambda;,&alpha;)

If the x satisfies the constraints, then &theta;<sub>p</sub>(x) = f(x) as all the other terms are 0. So, our problem becomes, min<sub>x</sub> &theta;<sub>p</sub>(x) = min f(x) = p

2. **Dual Form** - 

&#8466;(x,&lambda;<sub>1</sub>,&lambda;<sub>2</sub>,...,&lambda;<sub>n</sub>,&alpha;<sub>1</sub>,&alpha;<sub>2</sub>,...,&alpha;<sub>m</sub>) = f(x) + &Sigma;&lambda;<sub>i</sub> h<sub>i</sub>(x) + &Sigma;&alpha;<sub>j</sub> g<sub>j</sub>(x) subject to the corresponding equality and inequality conditions.

The Dual form is : &theta;<sub>d</sub>(&alpha;,&lambda;) = min<sub>x</sub> &#8466;(x,&lambda;,&alpha;)

So, entire problem, max<sub>&alpha;,&lambda;</sub> min<sub>x</sub> &#8466;(x,&lambda;,&alpha;) = d

From the general fact mentioned above, min<sub>x</sub> max<sub>&alpha;</sub> f(x,&alpha;) &ge; max<sub>&alpha;</sub> min<sub>x</sub> f(x,&alpha;)

Comparing this with our situation, **d &le; p**

The two values d and p are equal when they staisfy a set of condition called **KKT conditions**. Following are the condition,

i. &nabla;<sub>x</sub> &#8466; = 0

ii. &nabla;<sub>&lambda;</sub> &#8466; = 0

iii. &alpha;<sub>j</sub> &ge; 0

iv. g<sub>j</sub> &le; 0

v. &alpha;<sub>j</sub> g<sub>j</sub> = 0

All these conditions are satisfied in our case and hence, we can solve the dual form instead of primal form if the primal form turns out to be a non convex problem and cannot be solved.

### Notation

The Notations used for SVM is slightly different from that of logistic regression where we used 0 and 1 for representing success and failure. SVM uses {-1, +1} for differetiating between classes. This technique uses vector approach and identifies a plane that separates both classes from each other.

### Theory (Problem Formulation)

First we will look at the theoretical part in the dimension of data and then look at how SVM transforms the data into higher dimension. Since, we are using a plane to separate the classes. The objective function will be the equation of a plane.

h(w,b) = w<sup>T</sup>x + b (This is the equation of a plane in linear algebra form and is equivalent to ax + by + cz + k = 0 in 3-D)

_where_ w = [&theta;<sub>1</sub>,&theta;<sub>2</sub>,...,&theta;<sub>n</sub>], x = [x<sub>1</sub>,x<sub>2</sub>,...,x<sub>n</sub>] and b = &theta;<sub>0</sub> in n-Dimnesion.

The objective is to maximize the distance between the nearest data point of each class (support vectors) and the plane. Below is an image showing a linealy separable dataset.

![SVM_Margin](/images/SVM/SVM_Margin.jpg)

Also, y<sup>(i)</sup>(w<sup>T</sup>x<sup>(i)</sup> + b) > 0 &Implies; data point correctly classified (If data point is on left side of the plane, the distance will be negative and if on the right side, it will be positive. This coupled with the notation of {-1, +1} always results in positive number for correct classifications)

**Note**: the denominator of ||w|| has been omitted here as it is always positive (equivalent to &#8730;(a<sup>2</sup> + b<sup>2</sup> + c<sup>2</sup>))

This metric is called functional margin, &gamma;&#770; <sup>(i)</sup> = y<sup>(i)</sup>(w<sup>T</sup>x<sup>(i)</sup> + b)

There is another metric called geometric margin, &gamma;<sup>(i)</sup> = <sup>&gamma;&#770; <sup>(i)</sup></sup> &frasl; <sub>||w||</sub>

Let's denote &gamma; = min &gamma;<sup>(i)</sup> 

So, our objective function would be,
max <sub>&gamma;, w,b</sub> &gamma; subject to constraint <sup>y<sup>(i)</sup>(w<sup>T</sup>x<sup>(i)</sup> + b)</sup> &frasl; <sub>||w||</sub> &ge; &gamma;

This basically means, we want to maximize the minimum margin with constraint that the distance between every data point and the plane is greater than or equal to this value. Representing this in the form of functional margin, 

max <sub>&gamma;, w,b</sub> <sup>&gamma;&#770;</sup> &frasl; <sub>||w||</sub> subject to constraint y<sup>(i)</sup>(w<sup>T</sup>x<sup>(i)</sup> + b) &ge; &gamma;&#770;

This problem is not solvable in its current form and hence, we need to perform certain manipulations. Notice in the definition of functional margin, &gamma;&#770; <sup>(i)</sup> = y<sup>(i)</sup>(w<sup>T</sup>x<sup>(i)</sup> + b), if we change w &rarr; 2w and b &rarr; 2b &Implies; &gamma;&#770; &rarr; 2&gamma;&#770;

This shows that it's possible to choose a reproportion value and rescale the entire objective to have maximum functional margin = 1. Therefore, rescaling we get the our objective function as, 

max <sub>&gamma;, w,b</sub> <sup>1</sup> &frasl; <sub>||w||</sub> subject to constraint y<sup>(i)</sup>(w<sup>T</sup>x<sup>(i)</sup> + b) &ge; 1

This will be same as, min <sub>&gamma;, w,b</sub> <sup>||w||<sup>2</sup></sup> &frasl; <sub>2</sub> subject to constraint y<sup>(i)</sup>(w<sup>T</sup>x<sup>(i)</sup> + b) &ge; 1 

### Theory (Problem Solution)

In order to solve our problem, we will be using the Lagrangian Method described above in the pre-requiste section. Here, we have an objective function we want to minimize subject to an inequality constraint.

So, objective function : f(w) = <sup>||w||<sup>2</sup></sup> &frasl; <sub>2</sub>

Inequality constraints : g<sub>i</sub>(w,b) = y<sup>(i)</sup>(w<sup>T</sup>x<sup>(i)</sup> + b) - 1 

Therefore, we define a lagrangian function, **&#8466;(w,b,&alpha;) =  <sup>||w||<sup>2</sup></sup> &frasl; <sub>2</sub> - &Sigma;<sub>i</sub><sup>m</sup> &alpha;<sub>i</sub> [y<sup>(i)</sup>(w<sup>T</sup>x<sup>(i)</sup> + b) - 1]**

Conditions to minimize the lagrangian is, &nabla;<sub>w</sub> L = 0 and &nabla;<sub>b</sub> L = 0

Applying these conditions, we get, w = &Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub> y<sup>(i)</sup> x<sup>(i)</sup> and &Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub> y<sup>(i)</sup> = 0     - (Reference Equation 1)

Once, we get w (the value that decide the orientation of the plane), to obtain b (decides the parallel movement of plane) is easy. The plane would be at the mid point of the distance between closest data points of both classes (No class gets priority).

So, **b = <sup>max<sub>y = -1</sub> w<sup>T</sup>x<sup>(i)</sup> + min<sub>y = 1</sub> w<sup>T</sup>x<sup>(i)</sup></sup> &frasl; <sub>2</sub>**

Also, replacing the value of w in our prediction function, w<sup>T</sup>x + b = (&Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub> y<sup>(i)</sup> x<sup>(i)</sup>)x + b

&Implies; w<sup>T</sup>x + b = &Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub> y<sup>(i)</sup> (x<sup>(i)</sup>)<sup>T</sup>x + b

Observe the term, (x<sup>(i)</sup>)<sup>T</sup>x. This is the product of training data points and new data point to be classified. It is also written as <x<sup>(i)</sup>,x> and is also called inner product.

If we look carefully at the prediciton function, the value of &alpha;<sub>i</sub> = 0 whenever g<sub>i</sub>(w,b) &ne; 0 (Refer Prerequisite above) and hence, the prediciton will only depend on those training data points where g<sub>i</sub>(w,b) = 0. This happens only for the data points closest to the plane. This is the reason these closest data points are called **support vectors**.

Now, the only thing unkown to us is &alpha;<sub>i</sub>. For this, we will be using the primal and dual form explained above in the pre-requisite section. 

Primal Form of the Lagrangian function, &theta;<sub>p</sub> = max<sub>&alpha;</sub> &#8466;(w,b,&alpha;) = f(w,b)

so, objective : min<sub>w,b</sub>  f(w,b) (This is again not solvable, So, we resort to Dual form of the problem)

and Dual Form of the Lagrangian function, &theta;<sub>d</sub> = min<sub>w,b</sub> &#8466;(w,b,&alpha;)

Let's solve the Lagrangian first by using value of w obtained above in order to calculate &theta;<sub>d</sub>

&#8466;(w,b,&alpha;) =  <sup>||w||<sup>2</sup></sup> &frasl; <sub>2</sub> - &Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub> [y<sup>(i)</sup>(w<sup>T</sup>x<sup>(i)</sup> + b) - 1]

&Implies; &#8466;(w,b,&alpha;) = <sup>(&Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub> y<sup>(i)</sup> x<sup>(i)</sup>)(&Sigma;<sub>j=1</sub><sup>m</sup> &alpha;<sub>j</sub> y<sup>(j)</sup> x<sup>(j)</sup>)</sup> &frasl; <sub>2</sub> - &Sigma;<sub>i</sub><sup>m</sup> &alpha;<sub>i</sub> [y<sup>(i)</sup> { (&Sigma;<sub>j=1</sub><sup>m</sup> &alpha;<sub>j</sub> y<sup>(j)</sup> x<sup>(j)</sup>) x<sup>(i)</sup> + b} - 1]

&Implies; &#8466;(w,b,&alpha;) = <sup>(&Sigma;<sub>i,j=1</sub><sup>m</sup> &alpha;<sub>i</sub>&alpha;<sub>j</sub> y<sup>(i)</sup>y<sup>(j)</sup> (x<sup>(i)</sup>)<sup>T</sup> x<sup>(j)</sup>)</sup> &frasl; <sub>2</sub> - &Sigma;<sub>i,j=1</sub><sup>m</sup> &alpha;<sub>i</sub>&alpha;<sub>j</sub> y<sup>(i)</sup>y<sup>(j)</sup> (x<sup>(i)</sup>)<sup>T</sup> x<sup>(j)</sup> - b &Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub> y<sup>(i)</sup> + &Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub>

From Reference Equation 1 above, the third term is 0

&Implies; &#8466;(w,b,&alpha;) =  &Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub> - (<sup>1</sup>&frasl;<sub>2</sub>)&Sigma;<sub>i,j=1</sub><sup>m</sup> &alpha;<sub>i</sub>&alpha;<sub>j</sub> y<sup>(i)</sup>y<sup>(j)</sup> (x<sup>(i)</sup>)<sup>T</sup> x<sup>(j)</sup>

Now,the above equation is only function of &alpha;<sub>i</sub>. So pluging this into our dual form,

max<sub>&alpha;</sub> &theta;<sub>d</sub>(&alpha;) = max<sub>&alpha;</sub> &Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub> - (<sup>1</sup>&frasl;<sub>2</sub>)&Sigma;<sub>i,j=1</sub><sup>m</sup> &alpha;<sub>i</sub>&alpha;<sub>j</sub> y<sup>(i)</sup>y<sup>(j)</sup> (x<sup>(i)</sup>)<sup>T</sup> x<sup>(j)</sup> subject to contraints &alpha;<sub>i</sub> &ge; 0 and &Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub> y<sup>(i)</sup> = 0

&Implies; **max<sub>&alpha;</sub> &theta;<sub>d</sub>(&alpha;) = max<sub>&alpha;</sub> &Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub> - (<sup>1</sup>&frasl;<sub>2</sub>)&Sigma;<sub>i,j=1</sub><sup>m</sup> &alpha;<sub>i</sub>&alpha;<sub>j</sub> y<sup>(i)</sup>y<sup>(j)</sup> <x<sup>(i)</sup>,x<sup>(j)</sup>> subject to contraints &alpha;<sub>i</sub> &ge; 0 and &Sigma;<sub>i=1</sub><sup>m</sup> &alpha;<sub>i</sub> y<sup>(i)</sup> = 0**

The way we solve this is, we vary two &alpha;'s at a time and optimize the function according to it (We cannot vary one at a time because varying one keeping others constant would violate the second constraint). So, vary &alpha;<sub>1</sub> and &alpha;<sub>2</sub> together. 

&alpha;<sub>1</sub>y<sub>1</sub> + &alpha;<sub>2</sub>y<sub>2</sub> = k

&Implies; &alpha;<sub>1</sub> = <sup>(k - &alpha;<sub>2</sub>y<sub>2</sub>)</sup> &frasl; <sub>y<sub>1</sub></sub>

therefore, &theta;<sub>d</sub>(&alpha;) will be of the form a&alpha;<sub>2</sub><sup>2</sup> + b&alpha;<sub>2</sub> + c which is a solvable quadratic equation. Post this, we will maximize the function for another set of &alpha's. This is called as Sequential Minimal Optimization (SMO Algorithm). Following image describes how this would work when varying one &alpha; at a time in 2-D (Coordinate Ascent Algorithm)

![Coordinate_ascent](/images/SVM/Coordinate_ascent.jpg)

### Kernels

A very important point to notice above is in both the prediction function and the final objective function, the involvement of data point is in their inner product form <x<sup>(i)</sup>,x<sup>(j)</sup>>. The values x<sup>(i)</sup> and x<sup>(j)</sup> here are the feature sets of data and this form helps us as we can just replace them with any other feature set and nothing else needs to change. The other feature set is generally one with a higher dimension and is represented in inner product form as <&Phi;(x)<sup>(i)</sup>,&Phi;(x)<sup>(j)</sup>>.

This higher dimension can be computationally very inefficient and might take very long time to calculate but what if we could somehow represent this inner product through some function that can be computed very easily. These functions are called **Kernal function**. Let's take an example for this -

Let K(x,z) = (x<sup>T</sup>z)<sup>2</sup>

&Implies; K(x,z) = (&Sigma;<sub>i=1</sub><sup>m</sup> x<sub>i</sub>z<sub>i</sub>) (&Sigma;<sub>j=1</sub><sup>m</sup> x<sub>j</sub>z<sub>j</sub>)

&Implies; K(x,z) = &Sigma;<sub>i,j=1</sub><sup>m</sup> (x<sub>i</sub>x<sub>j</sub>)(z<sub>i</sub>z<sub>j</sub>)

So, if we consider x to be in 3-D, here &Phi;(x) = [x<sub>1</sub>x<sub>1</sub>, x<sub>1</sub>x<sub>2</sub>, x<sub>1</sub>x<sub>3</sub>, x<sub>2</sub>x<sub>2</sub>, x<sub>2</sub>x<sub>3</sub>, x<sub>3</sub>x<sub>3</sub>]

By considering the Kernel function mentioned above, we moved from 3-D to 6-D space. Also, this way instead of calculating the &Phi;(x), we directly calculate the inner product which is computationally very efficient.

There are lots of commonly used Kernel functions with the most common being Guassian Kernel, K(x,y) = exp(- <sup>||x - y||<sup>2</sup></sup> &frasl; <sub>2&sigma;<sup>2</sup></sub>)

In order to see the &phi;(x) for guassian kernel, we can use taylor expnasion for exp(x). This will show us that this kernel takes our us to infinite dimensional space.


